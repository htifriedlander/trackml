{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.31738261840044, 72.15091393575189, 116.0946312221527, 172.07253929769357, 260.3569293324722, 360.3101542051449, 500.2151479081191, 660.12508634391, 820.1546870692688, 1020.1106909393304]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from trackml.dataset import load_event, load_dataset \n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event \n",
    "import os\n",
    "import math\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "%matplotlib notebook\n",
    "%run utils.ipynb\n",
    "%run all_create.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hits, cells, particles, truth = load_data_single_event(1050)\n",
    "hits_from_seeds = np.load('./hits_from_seeds.npy')\n",
    "print (hits.head())\n",
    "hits_array = np.array (hits.get_values())\n",
    "mapping = np.argsort (hits_array[:,0])\n",
    "hits_array = hits_array[mapping]\n",
    "print (hits_array)\n",
    "hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def predict_next_hit(hits_so_far):\n",
    "    n_steps = len(hits_so_far[0])\n",
    "    n_input_features = 5\n",
    "    n_neurons = 200\n",
    "    n_outputs = 3\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_input_features], name='input')\n",
    "    \n",
    "    lstm = tf.contrib.rnn.LSTMCell(num_units = n_neurons, use_peepholes = True)\n",
    "    lstm_cell = tf.contrib.rnn.OutputProjectionWrapper(lstm, output_size = n_outputs, reuse=tf.AUTO_REUSE)\n",
    "    rnn_outputs, states = tf.nn.dynamic_rnn(lstm_cell, X, dtype = tf.float32)\n",
    "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "    print_op = tf.Print(rnn_outputs, [rnn_outputs], name='print_pred')\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as lstm3sess:\n",
    "\n",
    "        init.run()\n",
    "        initial_step = global_step.eval()\n",
    "        saver = tf.train.Saver()\n",
    "        writer = tf.summary.FileWriter('./logs/lstm3', lstm3sess.graph)\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpoints/lstm3/'))\n",
    "        # if that checkpoint exists, restore from checkpoint\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(lstm3sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        x_data = hits_so_far\n",
    "        test_print = lstm3sess.run(print_op, feed_dict={X:x_data})\n",
    "        return [test_print[0][-1][0], test_print[0][-1][1], test_print[0][-1][2]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Encapsulates the NN used for next-hit prediction \n",
    "\"\"\"\n",
    "class predict_engine(): \n",
    "    N_steps = 10\n",
    "    N_INPUT_FEATURES = 5\n",
    "    N_NEURONS = 200\n",
    "    N_OUTPUTS = 3\n",
    "    MODEL_PATH = './checkpoints/baseline-idealv4/-33103.meta'\n",
    "    \n",
    "    def __init__(self):\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        infSess = tf.Session() \n",
    "        init.run(session = infSess)\n",
    "            \n",
    "        saver = tf.train.import_meta_graph(self.MODEL_PATH)\n",
    "        graph = saver.restore(infSess,'./checkpoints/baseline-idealv4/-33103' )\n",
    "        #graph = tf.get_default_graph #hopefully this always points to the right one...\n",
    "        predict_op = infSess.graph.get_tensor_by_name(\"print_op:0\")\n",
    "        self.predict_op = predict_op\n",
    "        self.infSess = infSess \n",
    "    \n",
    "    def pred(self, seed):\n",
    "        #print('seed shape is:')\n",
    "        #print(seed.shape)\n",
    "        pad_zeros = 10 - len(seed)\n",
    "        x_data = np.array([np.pad(seed, ((0, pad_zeros), (0,0)), 'constant')])\n",
    "        #print('x_data shape is:')\n",
    "        #print(x_data.shape)\n",
    "        \n",
    "        inputs = tf.placeholder(tf.float32, [None, 10, 5])\n",
    "        input_tensor = self.infSess.graph.get_tensor_by_name('input_ph:0')\n",
    "        prediction = self.infSess.run(self.predict_op, feed_dict={input_tensor:x_data})\n",
    "        #print('input was: ')\n",
    "        #print(x_data)\n",
    "        #print('\\n')\n",
    "        #print('pred is: ')\n",
    "        #print(prediction)\n",
    "        return prediction[0]\n",
    "    \n",
    "    def close(self):\n",
    "        self.infSess.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#tf_init_start = time.time()\n",
    "prediction = predict_engine()\n",
    "prediction.load()\n",
    "#tf_init_end = time.time()\n",
    "\n",
    "#init_seed_start = time.time()\n",
    "seeds = next_seed(hits_from_seeds)\n",
    "#init_seed_end = time.time()\n",
    "\n",
    "\n",
    "hits_from_tracks = []\n",
    "mse_hitid = []\n",
    "#austin_start_time = time.time()\n",
    "\n",
    "#total_pred_time = 0\n",
    "#total_track_pass_time = 0\n",
    "#get_xyz_total = 0\n",
    "#get_hit_info_total = 0\n",
    "#mse_total = 0\n",
    "#process_time_total = 0\n",
    "for i in range(5):#change it back to 5\n",
    "    mse_hitid.append([])\n",
    "    feed_seed = next(seeds)[0]\n",
    "    #print('feed_seed is: ')\n",
    "    #print(feed_seed)\n",
    "    \n",
    "    for j in range(7):\n",
    "        #print(\"j: \", j)\n",
    "       \n",
    "        #pred_start = time.time()\n",
    "        predicted_hit = prediction.pred(feed_seed)[j+2]\n",
    "        #pred_end = time.time()\n",
    "        \n",
    "        \n",
    "        #print('NN pred time: ' + str(pred_end -pred_start))\n",
    "        \n",
    "        predicted_hit_xyz = polar_to_cartesian(predicted_hit[0], predicted_hit[1], predicted_hit[2])\n",
    "        \n",
    "                \n",
    "        #track_pass_init = time.time()\n",
    "        real_hit_id = calc_dist(predicted_hit_xyz[0], predicted_hit_xyz[1], predicted_hit_xyz[2], hits_array)\n",
    "        #track_pass_end = time.time()\n",
    "        \n",
    "        \n",
    "        #get_xyz_init = time.time()\n",
    "        real_hit = get_xyz(real_hit_id)\n",
    "        #get_xyz_end = time.time()\n",
    "        #get_xyz_total +=(get_xyz_end - get_xyz_init)\n",
    "        \n",
    "        #get_hit_info_init = time.time()\n",
    "        l, v, hit_id = get_hit_info(real_hit[0], real_hit[1], real_hit[2]) #change function to take hits df as parameter\n",
    "        #get_hit_info_end = time.time()\n",
    "        #get_hit_info_total += (get_hit_info_end - get_hit_info_init)\n",
    "        \n",
    "        #mse_init = time.time()\n",
    "        mse = distance_between_two_points(real_hit, polar_to_cartesian(predicted_hit[0], predicted_hit[1], predicted_hit[2]))\n",
    "        #mse_end = time.time()\n",
    "        #reshape_init = time.time()\n",
    "        mse_hitid[i].extend([[mse, real_hit_id]])\n",
    "        real_hit.extend([l,v])\n",
    "        reshaped_real_hit = np.asarray(real_hit).reshape(1, 5)\n",
    "        feed_seed = np.append(feed_seed, reshaped_real_hit, axis=0)\n",
    "        #reshape_end = time.time()\n",
    "        \n",
    "        \n",
    "        #mse_total += (mse_end - mse_init)\n",
    "        #process_time_total += (reshape_end - reshape_init)\n",
    "        #total_pred_time += (pred_end - pred_start)\n",
    "        #total_track_pass_time +=(track_pass_end - track_pass_init)\n",
    "        #print('track pass time: '+str(track_pass_end - track_pass_init))\n",
    "    #print ('this time it was ' + str (pred_end - pred_start))\n",
    "    #print ('but track pass time was ' + str (track_pass_end - track_pass_init))\n",
    "    hits_from_tracks.append(feed_seed)\n",
    "#final_end = time.time()\n",
    "#print('total runtime: ' + str(final_end -austin_start_time))\n",
    "#print('get xyz_total time: ',get_xyz_total)\n",
    "#print('get hit info total: ',get_hit_info_total)\n",
    "#print('tf graph load: ' + str(tf_init_end - tf_init_start))\n",
    "#print('total NN pred time: ',total_pred_time)\n",
    "#print('total track pass time: ',total_track_pass_time)\n",
    "#print('total mse calc time: ', mse_total)\n",
    "#print('reshaping time: ', process_time_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_track_from_seed (feed_seed, hits_array):\n",
    "    mse_hitid = []\n",
    "    for j in range(7):\n",
    "        predicted_hit = prediction.pred(feed_seed)[j+2]\n",
    "        predicted_hit_xyz = polar_to_cartesian(predicted_hit[0], predicted_hit[1], predicted_hit[2])\n",
    "        (real_hit_id, dist_squared) = calc_dist(predicted_hit_xyz[0], predicted_hit_xyz[1], predicted_hit_xyz[2], hits_array)\n",
    "        hit_index = int (np.round (real_hit_id - 1))\n",
    "        assert (hits_array[hit_index,0] == real_hit_id)\n",
    "        x, y, z, l, v = hits_array[hit_index,1], hits_array[hit_index,2], hits_array[hit_index,3], hits_array[hit_index,5], hits_array[hit_index,4]\n",
    "        r, phi, z = cartesian_to_3d_polar (x, y, z)\n",
    "        to_append = np.array ([[r, phi, z, l, v]])\n",
    "        feed_seed = np.append (feed_seed, to_append, axis = 0)\n",
    "        mse_hitid.append ([dist_squared, real_hit_id])\n",
    "        continue\n",
    "    return (feed_seed, mse_hitid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_event (seeds, hits):\n",
    "    hits_array = np.array (hits.get_values())\n",
    "    hits_from_seeds = rpzlv_from_seeds (seeds, hits)\n",
    "    seeds_generated = next_seed(hits_from_seeds)\n",
    "    hits_from_tracks = []\n",
    "    mse_hitid = []\n",
    "    count = 0\n",
    "    for feed_seed in seeds_generated:\n",
    "        feed_seed = np.array (feed_seed[0])\n",
    "        seed_mse_hitid = [[0, seeds[count,0]],[0, seeds[count,1]],[0, seeds[count,2]]]\n",
    "        (feed_seed, track_mse_hitid) = reconstruct_track_from_seed (feed_seed, hits_array)\n",
    "        hits_from_tracks.append (feed_seed)\n",
    "        mse_hitid.append (seed_mse_hitid + track_mse_hitid)\n",
    "        count += 1\n",
    "       \n",
    "    return (hits_from_tracks, mse_hitid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_test_events ():\n",
    "    itr = load_dataset ('./data/test_data', parts = ['hits'])\n",
    "    for event_data in itr:\n",
    "        event_id = event_data[0]\n",
    "        print ('now working on event number ' + str (event_id))\n",
    "        if (event_id <= 43):\n",
    "            continue\n",
    "        hits = event_data[1]\n",
    "        hits_trans = trans_to_cylindrical (hits)\n",
    "        seeds = np.load ('./seeds/test_event_' + str(event_id) + '_.npy')\n",
    "        yield reconstruct_event (seeds, hits), event_id#yield (hits_from_event, hit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/allv1/model.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'event_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d65a41b91f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./seeds/training_event_v2_1050.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreconstructed_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_hitid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstruct_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'./experimental/hits_from_tracks_event_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhits_from_tracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'./experimental/mse_hitid_event_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmse_hitid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'event_id' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = predict_engine()\n",
    "prediction.load()\n",
    "hit_df, _, _,_ = load_data_single_event(1050)\n",
    "start_time = time.time()\n",
    "seeds = np.load('./seeds/training_event_v2_1050.npy')\n",
    "reconstructed_tracks, mse_hitid = reconstruct_event(seeds, hit_df)\n",
    "np.save ('./experimental/hits_from_tracks_event_' + str (1050) + '.npy', np.array (hits_from_tracks))\n",
    "np.save ('./experimental/mse_hitid_event_' + str (1050) + '.npy', np.array (mse_hitid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save ('./experimental/hits_from_tracks_event_' + str (1050) + '.npy', np.array (reconstructed_tracks))\n",
    "np.save ('./experimental/mse_hitid_event_' + str (1050) + '.npy', np.array (mse_hitid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_engine()\n",
    "prediction.load()\n",
    "start_time = time.time()\n",
    "for (hits_from_tracks, mse_hitid), event_id in reconstruct_test_events():\n",
    "    print ('now saving event number ' + str (event_id))\n",
    "    print ('elapsed time is ' + str ((time.time() - start_time)/60/60) + ' hours.')\n",
    "    np.save ('./reconstructed_test_events/hits_from_tracks_event_' + str (event_id) + '.npy', np.array (hits_from_tracks))\n",
    "    np.save ('./reconstructed_test_events/mse_hitid_event_' + str (event_id) + '.npy', np.array (mse_hitid))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_time = time.time()\n",
    "prediction = predict_engine()\n",
    "prediction.load()\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "number_to_do = len (hits_from_seeds)\n",
    "\n",
    "for feed_seed in seeds:#change it back to 5\n",
    "    feed_seed = np.array (feed_seed[0])\n",
    "    (feed_seed, track_mse_hitid) = reconstruct_track_from_seed (feed_seed)\n",
    "    hits_from_tracks.append (feed_seed)\n",
    "    mse_hitid.append (track_mse_hitid)\n",
    "    #print (counter % int (number_to_do/100))\n",
    "    if (counter % int (number_to_do/100) k== 0):\n",
    "        print (counter/number_to_do)\n",
    "    counter += 1\n",
    "\n",
    "print (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "prediction = predict_engine()\n",
    "prediction.load()\n",
    "hits, cells, particles, truth = load_data_single_event(1050)\n",
    "seeds = np.load ('./seeds/training_event_1050.npy')\n",
    "(hits_from_tracks, mse_hitid) = reconstruct_event (seeds, hits)\n",
    "np.save ('./hits_from_tracks.npy', np.array (hits_from_tracks))\n",
    "np.save ('./mse_hitid.npy', np.array (mse_hitid))\n",
    "print('pipeline time for single event:',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save ('./tracksToPlot.npy', np.array (hits_from_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = np.load('./mse_hitid.npy')\n",
    "track_cand = np.load('./hits_from_tracks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_cand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
