{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cylinder (volume_id, layer_id):\n",
    "    return (((volume_id == 8 or volume_id == 13) and layer_id in [2,4,6,8])\n",
    "           or (volume_id == 17 and layer_id in [2,4]))\n",
    "\n",
    "\n",
    "def layer_number (volume_id, layer_id):\n",
    "    assert (volume_id in [8, 13, 17]), \"This volume_id is not in a cylinder!\"\n",
    "    assert (((volume_id == 8 or volume_id == 13) and layer_id in [2,4,6,8])\n",
    "           or (volume_id == 17 and layer_id in [2,4])), \"This layer_id is not in this volume_id\"\n",
    "    diction = {(8,2):1, (8,4):2, (8,6):3, (8,8):4, (13,2):5, (13,4):6, (13,6):7, (13,8):8, (17,2):9, (17,4):10}\n",
    "    return diction[(volume_id, layer_id)]\n",
    "\n",
    "\"\"\"\n",
    "returns dataframe of hits that only lie on cylinders for a given event\n",
    "\"\"\"\n",
    "def get_cylinder_hits(hit_dataframe, truth_dataframe ):\n",
    "    \n",
    "    volume_layer_list = [(8,2),(8,4),(8,6),(8,8),(13,2),(13,4),(13,6),(13,8),(17,2),(17,4)]\n",
    "    temp = [] \n",
    "    merge_by_hit_ids = hit_dataframe.merge(truth_dataframe, how = 'inner', on ='hit_id')\n",
    "    for pair in volume_layer_list:\n",
    "        volume, layer = pair\n",
    "        test_data = merge_by_hit_ids[(merge_by_hit_ids['volume_id'].values == volume) & (merge_by_hit_ids['layer_id'].values == layer)]\n",
    "        temp.append(test_data)\n",
    "    return pd.concat(temp)\n",
    "    \n",
    "#set full_tracks flag if looking for tracks of len 10\n",
    "#set ideal flag if looking for tracks of len 10 and only 1 hit per layer\n",
    "#setting ideal flag will set/override full_tracks flag\n",
    "\n",
    "def gen_simple_tracks(hit_df, truth_df, full_tracks = False, ideal = False, debug=False):\n",
    "    if ideal is True:\n",
    "        full_tracks = True\n",
    "    assert(isinstance(hit_df, pd.DataFrame) and isinstance(truth_df, pd.DataFrame))\n",
    "    hit_and_truth = get_cylinder_hits(hit_df, truth_df)\n",
    "    prelim_tracks = gen_tracks(hit_and_truth).values\n",
    "    if full_tracks is False:\n",
    "        return prelim_tracks \n",
    "    \n",
    "    #full_tracks flag must be true at this point\n",
    "    rows_to_remove = []\n",
    "    for row, track in enumerate(prelim_tracks):\n",
    "        if len(track) is not 10: #10 for each vol-layer in detector\n",
    "            rows_to_remove.append(row)\n",
    "    full_tracks = np.delete(prelim_tracks, rows_to_remove)\n",
    "    if ideal is False:\n",
    "        if debug:\n",
    "            print('prelim track num: '+str(len(prelim_tracks)))\n",
    "            print('removed tracks: '+str(len(rows_to_remove)))\n",
    "            print('remaining tracks: '+str(len(prelim_tracks) - len(rows_to_remove)))\n",
    "        return full_tracks\n",
    "    \n",
    "    #ideal flag must be true at this point\n",
    "    bad_rows = []\n",
    "    compare = [x for x in range(1,11)] #to guarantee each hit in track per layer\n",
    "    for idx, track in enumerate(full_tracks):\n",
    "        layer_nums = []\n",
    "        for hit in track:\n",
    "            vol_id = hits.loc[hits['hit_id']==hit]['volume_id'].item()\n",
    "            lay_id = hits.loc[hits['hit_id']==hit]['layer_id'].item()\n",
    "            layer_nums.append(layer_number(vol_id, lay_id))\n",
    "        if layer_nums != compare:\n",
    "            bad_rows.append(idx)\n",
    "    ideal_tracks = np.delete(full_tracks, bad_rows)\n",
    "    if debug:\n",
    "        print('full tracks: '+str(len(full_tracks)))\n",
    "        print('non-ideal tracks: '+str(len(bad_rows)))\n",
    "        print('ideal tracks: '+str(len(ideal_tracks)))\n",
    "    return ideal_tracks \n",
    "            \n",
    "def simple_batch_iter(hit_df, truth_df, batch_size, full_tracks = False, ideal = False):\n",
    "    if ideal is True:\n",
    "        full_tracks = True\n",
    "    tracks = gen_simple_tracks(hit_df, truth_df, full_tracks, ideal)\n",
    "    np.random.shuffle(tracks)\n",
    "    remainder = len(tracks) % ba\n",
    "    tch_size if len(tracks) % batch_size is not 0 else 0\n",
    "    if remainder is not 0:\n",
    "        modded_tracks = tracks[:-remainder]\n",
    "    else:\n",
    "        modded_tracks = tracks \n",
    "    assert(len(modded_tracks)%batch_size is 0)\n",
    "    for batch in modded_tracks.reshape(-1,batch_size,1):\n",
    "        yield batch\n",
    "        \n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(max_seq_len, batch_size, feature_len, truth_df, hits_df, simple = False, full_tracks = False, ideal = False):\n",
    "    hits = hits_df\n",
    "    max_seq_len = max_seq_len\n",
    "    if ideal is True:\n",
    "        full_tracks = True\n",
    "    if full_tracks is True:\n",
    "        max_seq_len = 10\n",
    "    b_size = batch_size\n",
    "    features = feature_len #xyz or phi r z\n",
    "    if simple is True:\n",
    "        all_data = list(simple_batch_iter(hits_df, truth_df, batch_size, full_tracks, ideal))\n",
    "    else:\n",
    "        all_data = list(batch_iter(truth_df,b_size))\n",
    "    \n",
    "    #print(all_data)\n",
    "    for result in all_data:\n",
    "        batch = []\n",
    "        batch_lv = []\n",
    "        labels_tensor = []\n",
    "        labels_tensor_lv = []\n",
    "        for track_list in result:\n",
    "            for hit_id in track_list:\n",
    "                hit_coord = []\n",
    "                track = []\n",
    "                track_lb = []\n",
    "                lv_pair = []\n",
    "                lv_tensor = []\n",
    "                label_coord = []\n",
    "                for elem in hit_id:\n",
    "                    x, y, z, layer_id, volume_id = hits.loc[hits['hit_id']== elem]['x'].item(), hits.loc[hits['hit_id']== elem]['y'].item(), hits.loc[hits['hit_id']== elem]['z'].item(), hits.loc[hits['hit_id'] == elem]['volume_id'].item(), hits.loc[hits['hit_id'] == elem]['layer_id'].item()\n",
    "                    r,phi,z = cartesian_to_3d_polar(x,y,z)\n",
    "                    hit_coord = [r,phi,z,layer_id, volume_id]\n",
    "                    label_coord = [r,phi,z]\n",
    "                    track.append(hit_coord)\n",
    "                    track_lb.append(label_coord)\n",
    "                    layer, volume = hits.loc[hits['hit_id'] == elem]['volume_id'].item(), hits.loc[hits['hit_id'] == elem]['layer_id'].item()\n",
    "                    lv_pair = [layer, volume]\n",
    "                    lv_tensor.append(lv_pair)\n",
    "                zeros_to_add = max_seq_len - len(track)\n",
    "                if zeros_to_add > 0:\n",
    "                    add_array = np.zeros((zeros_to_add,feature_len))\n",
    "                    add_array_lb = np.zeros((zeros_to_add, 3)) #3 is hardcoded for xyz/rphiz\n",
    "                    add_array_lv = np.zeros((zeros_to_add, 2))\n",
    "                    np_data = np.array(track)\n",
    "                    np_data_lb = np.array(track_lb)\n",
    "                    np_data_lv = np.array(lv_tensor)\n",
    "                    padded_track_data  = np.append(np_data,add_array,axis=0)\n",
    "                \n",
    "                    padded_track_data_lb = np.append(np_data_lb, add_array_lb, axis=0)\n",
    "                    padded_track_data_lv = np.append(np_data_lv, add_array_lv, axis=0)\n",
    "                elif zeros_to_add < 0:\n",
    "                    modded_track = track[:zeros_to_add]\n",
    "                    modded_track_lv = lv_tensor[:zeros_to_add]\n",
    "                    modded_track_lb = track_lb[:zeros_to_add]\n",
    "                    padded_track_data_lb = np.array(modded_track_lb)\n",
    "                    padded_track_data = np.array(modded_track)\n",
    "                    padded_track_data_lv = np.array(modded_track_lv)\n",
    "                else:\n",
    "                    padded_track_data_lb = np.array(track_lb)\n",
    "                    padded_track_data = np.array(track)\n",
    "                    padded_track_data_lv = np.array(lv_tensor)\n",
    "            \n",
    "            row_label = padded_track_data_lb[1:]\n",
    "            row_label_lv = padded_track_data_lv[1:]\n",
    "            padded_row_label = np.append(row_label, np.zeros((1,3)), axis=0) #hardcoded 3 for xyz/rphiz\n",
    "            padded_row_label_lv = np.append(row_label_lv, np.zeros((1,2)), axis=0)\n",
    "            labels_tensor.append(padded_row_label)\n",
    "            labels_tensor_lv.append(padded_row_label_lv)\n",
    "            batch.append(padded_track_data)\n",
    "            batch_lv.append(padded_track_data_lv)\n",
    "            \n",
    "        padded_batch_data = np.array(batch)\n",
    "        padded_batch_data_lv = np.array(batch_lv)\n",
    "        padded_labels = np.array(labels_tensor)\n",
    "        padded_labels_lv = np.array(labels_tensor_lv)\n",
    "        #print(padded_labels)\n",
    "        #print(padded_labels_lv)\n",
    "        yield padded_batch_data, padded_labels, padded_batch_data_lv, padded_labels_lv\n",
    "        \n",
    "def next_batch(max_seq_len, batch_size, feature_len):\n",
    "    all_data = load_dataset('data/train_sample/', parts=['hits','truth'])\n",
    "    for data in all_data:\n",
    "        hit_df, truth_df = data[1], data[2]\n",
    "        yield from get_data(max_seq_len, batch_size, feature_len, truth_df, hit_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_single_event(event_number):\n",
    "    file_name = 'event00000' + str(event_number)\n",
    "    event_id = file_name\n",
    "    hits, cells, particles, truth = load_event('data/train_sample/'+event_id)\n",
    "    return hits, cells, particles, truth\n",
    "hits, cells, particles, truth_df = load_data_single_event(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = simple_batch_iter(hits,truth_df,5, full_tracks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = get_data(10,1,5,truth_df,hits, simple = True, full_tracks = True, ideal = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label, data_lv, label_lv = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  32.50954756,   -2.60091572,   -3.52813005,    8.        ,\n",
       "            2.        ],\n",
       "        [  71.69335542,   -2.57546852,   -5.94687986,    8.        ,\n",
       "            4.        ],\n",
       "        [ 115.59768922,   -2.54950431,   -8.87187958,    8.        ,\n",
       "            6.        ],\n",
       "        [ 171.74125643,   -2.51454731,  -12.69690037,    8.        ,\n",
       "            8.        ],\n",
       "        [ 260.65754778,   -2.45791464,  -18.60000038,   13.        ,\n",
       "            2.        ],\n",
       "        [ 362.64783232,   -2.39263539,  -24.60000038,   13.        ,\n",
       "            4.        ],\n",
       "        [ 500.95353664,   -2.30318113,  -34.20000076,   13.        ,\n",
       "            6.        ],\n",
       "        [ 660.62577792,   -2.19581995,  -45.        ,   13.        ,\n",
       "            8.        ],\n",
       "        [ 816.22507131,   -2.08794826,  -54.40000153,   17.        ,\n",
       "            2.        ],\n",
       "        [1016.6482781 ,   -1.9347321 ,  -76.        ,   17.        ,\n",
       "            4.        ]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  71.69335542,   -2.57546852,   -5.94687986],\n",
       "        [ 115.59768922,   -2.54950431,   -8.87187958],\n",
       "        [ 171.74125643,   -2.51454731,  -12.69690037],\n",
       "        [ 260.65754778,   -2.45791464,  -18.60000038],\n",
       "        [ 362.64783232,   -2.39263539,  -24.60000038],\n",
       "        [ 500.95353664,   -2.30318113,  -34.20000076],\n",
       "        [ 660.62577792,   -2.19581995,  -45.        ],\n",
       "        [ 816.22507131,   -2.08794826,  -54.40000153],\n",
       "        [1016.6482781 ,   -1.9347321 ,  -76.        ],\n",
       "        [   0.        ,    0.        ,    0.        ]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8,  2],\n",
       "        [ 8,  4],\n",
       "        [ 8,  6],\n",
       "        [ 8,  8],\n",
       "        [13,  2],\n",
       "        [13,  4],\n",
       "        [13,  6],\n",
       "        [13,  8],\n",
       "        [17,  2],\n",
       "        [17,  4]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8.,  4.],\n",
       "        [ 8.,  6.],\n",
       "        [ 8.,  8.],\n",
       "        [13.,  2.],\n",
       "        [13.,  4.],\n",
       "        [13.,  6.],\n",
       "        [13.,  8.],\n",
       "        [17.,  2.],\n",
       "        [17.,  4.],\n",
       "        [ 0.,  0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
