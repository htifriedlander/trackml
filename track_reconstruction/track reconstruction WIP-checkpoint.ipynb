{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from trackml.dataset import load_event, load_dataset \n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event \n",
    "import os\n",
    "import math\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "%matplotlib notebook\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_from_seeds = np.load('./hits_from_seeds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, cells, particles, truth = load_data_single_event(1050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    hits: tensor of samples x timesteps x features\n",
    "    bounds: K:V of x_max, x_min, y_max, y_min, z_max, z_min\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "assuming input is samples x [x_val,y_val,z_val]\n",
    "\"\"\"\n",
    "def calc_norm(xyz, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "    norm_x = ((xyz[0] - x_min)/(x_max - x_min))\n",
    "    norm_y = ((xyz[1] - y_min)/(y_max - y_min))\n",
    "    norm_z = ((xyz[2] - z_min)/(z_max - z_min))\n",
    "    return [norm_x,norm_y,norm_z]\n",
    "\n",
    "def norm_hits(hits, bounds):\n",
    "    assert ('x_max' and 'x_min' and 'y_max' and 'y_min' and 'z_max' and 'z_min' in bounds) or ('r_max' and 'r_min' and 'phi_max' and 'phi_min' and 'z_max' and 'z_min' in bounds)\n",
    "    return np.apply_along_axis(calc_norm, 1, hits, x_min = bounds['x_min'], x_max = bounds['x_max'], y_min = bounds['y_min'], y_max = bounds['y_max'], z_min = bounds['z_min'], z_max = bounds['z_max']) \n",
    "\n",
    "\n",
    "def calc_bounds():\n",
    "    bounds={'x_max':0, 'x_min':0, 'y_max':0, 'y_min':0, 'z_max':0, 'z_min':0}\n",
    "    for num in range(1000,1099):\n",
    "        file_name = 'event00000' + str(num)\n",
    "        hits, cells, particles, truth = load_event('data/train_sample/'+file_name)\n",
    "        event_x_max, event_x_min, event_y_max, event_y_min, event_z_max, event_z_min = hits['x'].max(), hits['x'].min(), hits['y'].max(), hits['y'].min(), hits['z'].max(), hits['z'].min() \n",
    "        if bounds['x_max'] < event_x_max:\n",
    "            bounds['x_max'] = event_x_max\n",
    "        if bounds['x_min'] > event_x_min:\n",
    "            bounds['x_min'] = event_x_min\n",
    "        if bounds['y_max'] < event_y_max:\n",
    "            bounds['y_max'] = event_y_max\n",
    "        if bounds['y_min'] > event_y_min:\n",
    "            bounds['y_min'] = event_y_min\n",
    "        if bounds['z_max'] < event_z_max:\n",
    "            bounds['z_max'] = event_z_max\n",
    "        if bounds['z_min'] > event_y_min:\n",
    "            bounds['z_min'] = event_y_min\n",
    "    return bounds\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "input: hits and truth dfs\n",
    "\n",
    "output: df of particle_id as index and list of particles \n",
    "\"\"\"\n",
    "\n",
    "def gen_tracks(truth_df):\n",
    "    assert(isinstance(truth_df, pd.DataFrame))\n",
    "    #print(truth_df)\n",
    "    truth_df['dist'] = np.sqrt(truth_df['tx']**2+truth_df['ty']**2+truth_df['tz']**2)\n",
    "    grouped = truth_df.groupby('particle_id')['hit_id','dist']\n",
    "    a = grouped.apply(lambda x: x.sort_values(by=['dist'],ascending=True))\n",
    "    final = a.groupby('particle_id')['hit_id'].apply(np.array)\n",
    "    return final \n",
    "\n",
    "##there's still a problem with how to deal with hits that have a particle id of 0\n",
    "\n",
    "def batch_iter(truth_df, batch_size):\n",
    "    tracks = gen_tracks(truth_df).values\n",
    "    np.random.shuffle(tracks) \n",
    "    remainder = len(tracks) % batch_size if len(tracks) % batch_size is not 0 else 0\n",
    "    if remainder is not 0:\n",
    "        modded_tracks = tracks[:-remainder]\n",
    "    else:\n",
    "        modded_tracks = tracks \n",
    "    assert(len(modded_tracks)%batch_size is 0)\n",
    "    for batch in modded_tracks.reshape(-1,batch_size,1):\n",
    "        yield batch\n",
    "        \n",
    "def get_data(max_seq_len, batch_size, feature_len, truth_df, hits_df):\n",
    "    hits = hits_df\n",
    "    max_seq_len = max_seq_len\n",
    "    b_size = batch_size\n",
    "    features = feature_len #xyz or phi r z\n",
    "    all_data = list(batch_iter(truth_df,b_size))\n",
    "    \n",
    "    #print(all_data)\n",
    "    for result in all_data:\n",
    "        batch = []\n",
    "        batch_lv = []\n",
    "        labels_tensor = []\n",
    "        labels_tensor_lv = []\n",
    "        for track_list in result:\n",
    "            for hit_id in track_list:\n",
    "                hit_coord = []\n",
    "                track = []\n",
    "                track_lb = []\n",
    "                lv_pair = []\n",
    "                lv_tensor = []\n",
    "                label_coord = []\n",
    "                for elem in hit_id:\n",
    "                    x, y, z, layer_id, volume_id = hits.loc[hits['hit_id']== elem]['x'].item(), hits.loc[hits['hit_id']== elem]['y'].item(), hits.loc[hits['hit_id']== elem]['z'].item(), hits.loc[hits['hit_id'] == elem]['volume_id'].item(), hits.loc[hits['hit_id'] == elem]['layer_id'].item()\n",
    "                    r,phi,z = cartesian_to_3d_polar(x,y,z)\n",
    "                    hit_coord = [r,phi,z,layer_id, volume_id]\n",
    "                    label_coord = [r,phi,z]\n",
    "                    track.append(hit_coord)\n",
    "                    track_lb.append(label_coord)\n",
    "                    layer, volume = hits.loc[hits['hit_id'] == elem]['volume_id'].item(), hits.loc[hits['hit_id'] == elem]['layer_id'].item()\n",
    "                    lv_pair = [layer, volume]\n",
    "                    lv_tensor.append(lv_pair)\n",
    "                zeros_to_add = max_seq_len - len(track)\n",
    "                if zeros_to_add > 0:\n",
    "                    add_array = np.zeros((zeros_to_add,feature_len))\n",
    "                    add_array_lb = np.zeros((zeros_to_add, 3)) #3 is hardcoded for xyz/rphiz\n",
    "                    add_array_lv = np.zeros((zeros_to_add, 2))\n",
    "                    np_data = np.array(track)\n",
    "                    np_data_lb = np.array(track_lb)\n",
    "                    np_data_lv = np.array(lv_tensor)\n",
    "                    padded_track_data  = np.append(np_data,add_array,axis=0)\n",
    "                \n",
    "                    padded_track_data_lb = np.append(np_data_lb, add_array_lb, axis=0)\n",
    "                    padded_track_data_lv = np.append(np_data_lv, add_array_lv, axis=0)\n",
    "                elif zeros_to_add < 0:\n",
    "                    modded_track = track[:zeros_to_add]\n",
    "                    modded_track_lv = lv_tensor[:zeros_to_add]\n",
    "                    modded_track_lb = track_lb[:zeros_to_add]\n",
    "                    padded_track_data_lb = np.array(modded_track_lb)\n",
    "                    padded_track_data = np.array(modded_track)\n",
    "                    padded_track_data_lv = np.array(modded_track_lv)\n",
    "                else:\n",
    "                    padded_track_data_lb = np.array(track_lb)\n",
    "                    padded_track_data = np.array(track)\n",
    "                    padded_track_data_lv = np.array(lv_tensor)\n",
    "            \n",
    "            row_label = padded_track_data_lb[1:]\n",
    "            row_label_lv = padded_track_data_lv[1:]\n",
    "            padded_row_label = np.append(row_label, np.zeros((1,3)), axis=0) #hardcoded 3 for xyz/rphiz\n",
    "            padded_row_label_lv = np.append(row_label_lv, np.zeros((1,2)), axis=0)\n",
    "            labels_tensor.append(padded_row_label)\n",
    "            labels_tensor_lv.append(padded_row_label_lv)\n",
    "            batch.append(padded_track_data)\n",
    "            batch_lv.append(padded_track_data_lv)\n",
    "        padded_batch_data = np.array(batch)\n",
    "        padded_batch_data_lv = np.array(batch_lv)\n",
    "        padded_labels = np.array(labels_tensor)\n",
    "        padded_labels_lv = np.array(labels_tensor_lv)\n",
    "        #print(padded_labels)\n",
    "        #print(padded_labels_lv)\n",
    "        yield padded_batch_data, padded_labels, padded_batch_data_lv, padded_labels_lv\n",
    "        \n",
    "def next_batch(max_seq_len, batch_size, feature_len):\n",
    "    all_data = load_dataset('data/train_sample/', parts=['hits','truth'])\n",
    "    for data in all_data:\n",
    "        hit_df, truth_df = data[1], data[2]\n",
    "        yield from get_data(max_seq_len, batch_size, feature_len, truth_df, hit_df)\n",
    "        \n",
    "def get_lv_id(x, y, z):\n",
    "    row = hits.loc[(hits['x'] == x) & (hits['y'] == y) & (hits['z'] == z)]\n",
    "    return int(row.iloc[0][4]), int(row.iloc[0][5])\n",
    "\n",
    "def next_seed(hits_from_seeds):\n",
    "    for seed in hits_from_seeds:\n",
    "        track_seed = seed.reshape(1,3,5)\n",
    "        yield track_seed.tolist()\n",
    "        \n",
    "def distance_between_two_points(p1, p2):\n",
    "    distance = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 + (p2[2] - p1[2])**2)\n",
    "    return distance\n",
    "\n",
    "def get_xyz(hit_id):\n",
    "    xyz = hits[hits[\"hit_id\"] == hit_id].iloc[:,1:4].values.tolist()[0]\n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "unique_lv_pairs = []\n",
    "for row in hits.iloc[:,4:6].itertuples():\n",
    "    lv_pair = (row[1], row[2])\n",
    "    if lv_pair not in unique_lv_pairs:\n",
    "        unique_lv_pairs.append(lv_pair)\n",
    "\n",
    "fcl_dict = {}\n",
    "for lv_pair in unique_lv_pairs:\n",
    "    lv = str(lv_pair[0]) + \"-\" + str(lv_pair[1])\n",
    "    inputs = tf.placeholder(tf.float32, [None, 1, 3])\n",
    "    num_outputs = 30\n",
    "    layer = tf.contrib.layers.fully_connected(inputs, num_outputs, activation_fn=tf.nn.relu)\n",
    "    fcl_dict[lv] = layer\n",
    "\n",
    "def get_fcl(layer_id, volume_id):\n",
    "    lv_pair = str(layer_id) + \"-\" + str(volume_id)\n",
    "    for key, value in fcl_dict.items():\n",
    "        if lv_pair == key:\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_hit(hits_so_far):\n",
    "    n_steps = len(hits_so_far[0])\n",
    "    n_input_features = 5\n",
    "    n_neurons = 200\n",
    "    n_outputs = 3\n",
    "    \n",
    "    \n",
    "    \n",
    "    restoreGraph = tf.train.import_meta_graph('./checkpoints/baseline-idealv4/-10802.meta')\n",
    "    #print_tensors_in_checkpoint_file(file_name='./checkpoints/baseline-idealv4/-10802', tensor_name='', all_tensors=True, all_tensor_names=True)\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_input_features], name='input')\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as pred_sess:\n",
    "\n",
    "        init.run()\n",
    "        #restoreGraph.restore(lstm3sess, './checkpoints/baseline-testv2/checkpoint')\n",
    "        #inputs = graph.get_tensor_by_name(\"input:0\")\n",
    "        #saver = tf.train.Saver()\n",
    "        graph = tf.get_default_graph()\n",
    "        #ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpoints/baseline-idealv4/'))\n",
    "        # if that checkpoint exists, restore from checkpoint\n",
    "        #if ckpt and ckpt.model_checkpoint_path:\n",
    "        #    saver.restore(pred_sess, ckpt.model_checkpoint_path)\n",
    "        restoreGraph.restore(pred_sess, tf.train.latest_checkpoint('./checkpoints/baseline-idealv4/'))\n",
    "        prediction = graph.get_tensor_by_name(\"print_op:0\")\n",
    "        x_data = hits_so_far\n",
    "        predicted_hit = pred_sess.run(prediction, feed_dict={X:x_data})\n",
    "        return [predicted_hit[0][-1][0], predicted_hit[0][-1][1], predicted_hit[0][-1][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "num predicted hits: 0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/baseline-idealv4/-11002\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'input_ph' with dtype float and shape [?,10,5]\n\t [[Node: input_ph = Placeholder[dtype=DT_FLOAT, shape=[?,10,5], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: rnn/transpose_1/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_151_rnn/transpose_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'input_ph', defined at:\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-b2051e1622f7>\", line 13, in <module>\n    predicted_hit = predict_next_hit(feed_seed)\n  File \"<ipython-input-6-056754fd73a6>\", line 7, in predict_next_hit\n    restoreGraph = tf.train.import_meta_graph('./checkpoints/baseline-idealv4/-10802.meta')\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1927, in import_meta_graph\n    **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 741, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 577, in import_graph_def\n    op_def=op_def)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_ph' with dtype float and shape [?,10,5]\n\t [[Node: input_ph = Placeholder[dtype=DT_FLOAT, shape=[?,10,5], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: rnn/transpose_1/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_151_rnn/transpose_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_ph' with dtype float and shape [?,10,5]\n\t [[Node: input_ph = Placeholder[dtype=DT_FLOAT, shape=[?,10,5], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: rnn/transpose_1/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_151_rnn/transpose_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b2051e1622f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num predicted hits: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(\"hits so far (feed_seed): \", feed_seed[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpredicted_hit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_hit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpredicted_hit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolar_to_cartesian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print(\"predicted_hit: \", predicted_hit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f0bd3717a249>\u001b[0m in \u001b[0;36mpredict_next_hit\u001b[0;34m(hits_so_far)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"print_op:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits_so_far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpredicted_hit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_hit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_ph' with dtype float and shape [?,10,5]\n\t [[Node: input_ph = Placeholder[dtype=DT_FLOAT, shape=[?,10,5], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: rnn/transpose_1/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_151_rnn/transpose_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'input_ph', defined at:\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-b2051e1622f7>\", line 13, in <module>\n    predicted_hit = predict_next_hit(feed_seed)\n  File \"<ipython-input-6-056754fd73a6>\", line 7, in predict_next_hit\n    restoreGraph = tf.train.import_meta_graph('./checkpoints/baseline-idealv4/-10802.meta')\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1927, in import_meta_graph\n    **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 741, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 577, in import_graph_def\n    op_def=op_def)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_ph' with dtype float and shape [?,10,5]\n\t [[Node: input_ph = Placeholder[dtype=DT_FLOAT, shape=[?,10,5], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: rnn/transpose_1/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_151_rnn/transpose_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "error = 100\n",
    "max_hits_per_tracks = 10\n",
    "seeded_hits = next_seed(hits_from_seeds)\n",
    "hits_from_tracks = []\n",
    "start = time.time()\n",
    "for i in range(2):\n",
    "    print(\"iteration: \" + str(i))\n",
    "    feed_seed = next(seeded_hits)\n",
    "    count = 0\n",
    "    while (len(feed_seed[0]) <= max_hits_per_tracks - 1):\n",
    "        print(\"num predicted hits: \" + str(count))\n",
    "        #print(\"hits so far (feed_seed): \", feed_seed[0])\n",
    "        predicted_hit = predict_next_hit(feed_seed)\n",
    "        predicted_hit = polar_to_cartesian(predicted_hit[0], predicted_hit[1], predicted_hit[2])\n",
    "        #print(\"predicted_hit: \", predicted_hit)\n",
    "        next_hit = get_xyz (closestHit (predicted_hit[0], predicted_hit[1], predicted_hit[2], hits) )\n",
    "        lv = get_lv_id(next_hit[0], next_hit[1], next_hit[2])\n",
    "        next_hit.extend((lv[0], lv[1]))\n",
    "        #print(\"next hit in sequence: \", next_hit)\n",
    "        if distance_between_two_points(predicted_hit, next_hit) > error:\n",
    "            break\n",
    "        feed_seed[0].append(next_hit)\n",
    "        #print(feed_seed[0])\n",
    "        count = count + 1\n",
    "    #print(feed_seed)\n",
    "    hits_from_tracks.append(feed_seed)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
