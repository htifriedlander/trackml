{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from trackml.dataset import load_event\n",
    "from trackml.dataset import load_dataset\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event \n",
    "%run utils.ipynb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  hit_id  track_id\n",
       "0         0       1         0\n",
       "1         0       2         0\n",
       "2         0       3         0\n",
       "3         0       4         0\n",
       "4         0       5         0\n",
       "5         0       6         0\n",
       "6         0       7         0\n",
       "7         0       8         0\n",
       "8         0       9         0\n",
       "9         0      10         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event000000000-cells.csv  event000000042-cells.csv  event000000084-cells.csv\r\n",
      "event000000000-hits.csv   event000000042-hits.csv   event000000084-hits.csv\r\n",
      "event000000001-cells.csv  event000000043-cells.csv  event000000085-cells.csv\r\n",
      "event000000001-hits.csv   event000000043-hits.csv   event000000085-hits.csv\r\n",
      "event000000002-cells.csv  event000000044-cells.csv  event000000086-cells.csv\r\n",
      "event000000002-hits.csv   event000000044-hits.csv   event000000086-hits.csv\r\n",
      "event000000003-cells.csv  event000000045-cells.csv  event000000087-cells.csv\r\n",
      "event000000003-hits.csv   event000000045-hits.csv   event000000087-hits.csv\r\n",
      "event000000004-cells.csv  event000000046-cells.csv  event000000088-cells.csv\r\n",
      "event000000004-hits.csv   event000000046-hits.csv   event000000088-hits.csv\r\n",
      "event000000005-cells.csv  event000000047-cells.csv  event000000089-cells.csv\r\n",
      "event000000005-hits.csv   event000000047-hits.csv   event000000089-hits.csv\r\n",
      "event000000006-cells.csv  event000000048-cells.csv  event000000090-cells.csv\r\n",
      "event000000006-hits.csv   event000000048-hits.csv   event000000090-hits.csv\r\n",
      "event000000007-cells.csv  event000000049-cells.csv  event000000091-cells.csv\r\n",
      "event000000007-hits.csv   event000000049-hits.csv   event000000091-hits.csv\r\n",
      "event000000008-cells.csv  event000000050-cells.csv  event000000092-cells.csv\r\n",
      "event000000008-hits.csv   event000000050-hits.csv   event000000092-hits.csv\r\n",
      "event000000009-cells.csv  event000000051-cells.csv  event000000093-cells.csv\r\n",
      "event000000009-hits.csv   event000000051-hits.csv   event000000093-hits.csv\r\n",
      "event000000010-cells.csv  event000000052-cells.csv  event000000094-cells.csv\r\n",
      "event000000010-hits.csv   event000000052-hits.csv   event000000094-hits.csv\r\n",
      "event000000011-cells.csv  event000000053-cells.csv  event000000095-cells.csv\r\n",
      "event000000011-hits.csv   event000000053-hits.csv   event000000095-hits.csv\r\n",
      "event000000012-cells.csv  event000000054-cells.csv  event000000096-cells.csv\r\n",
      "event000000012-hits.csv   event000000054-hits.csv   event000000096-hits.csv\r\n",
      "event000000013-cells.csv  event000000055-cells.csv  event000000097-cells.csv\r\n",
      "event000000013-hits.csv   event000000055-hits.csv   event000000097-hits.csv\r\n",
      "event000000014-cells.csv  event000000056-cells.csv  event000000098-cells.csv\r\n",
      "event000000014-hits.csv   event000000056-hits.csv   event000000098-hits.csv\r\n",
      "event000000015-cells.csv  event000000057-cells.csv  event000000099-cells.csv\r\n",
      "event000000015-hits.csv   event000000057-hits.csv   event000000099-hits.csv\r\n",
      "event000000016-cells.csv  event000000058-cells.csv  event000000100-cells.csv\r\n",
      "event000000016-hits.csv   event000000058-hits.csv   event000000100-hits.csv\r\n",
      "event000000017-cells.csv  event000000059-cells.csv  event000000101-cells.csv\r\n",
      "event000000017-hits.csv   event000000059-hits.csv   event000000101-hits.csv\r\n",
      "event000000018-cells.csv  event000000060-cells.csv  event000000102-cells.csv\r\n",
      "event000000018-hits.csv   event000000060-hits.csv   event000000102-hits.csv\r\n",
      "event000000019-cells.csv  event000000061-cells.csv  event000000103-cells.csv\r\n",
      "event000000019-hits.csv   event000000061-hits.csv   event000000103-hits.csv\r\n",
      "event000000020-cells.csv  event000000062-cells.csv  event000000104-cells.csv\r\n",
      "event000000020-hits.csv   event000000062-hits.csv   event000000104-hits.csv\r\n",
      "event000000021-cells.csv  event000000063-cells.csv  event000000105-cells.csv\r\n",
      "event000000021-hits.csv   event000000063-hits.csv   event000000105-hits.csv\r\n",
      "event000000022-cells.csv  event000000064-cells.csv  event000000106-cells.csv\r\n",
      "event000000022-hits.csv   event000000064-hits.csv   event000000106-hits.csv\r\n",
      "event000000023-cells.csv  event000000065-cells.csv  event000000107-cells.csv\r\n",
      "event000000023-hits.csv   event000000065-hits.csv   event000000107-hits.csv\r\n",
      "event000000024-cells.csv  event000000066-cells.csv  event000000108-cells.csv\r\n",
      "event000000024-hits.csv   event000000066-hits.csv   event000000108-hits.csv\r\n",
      "event000000025-cells.csv  event000000067-cells.csv  event000000109-cells.csv\r\n",
      "event000000025-hits.csv   event000000067-hits.csv   event000000109-hits.csv\r\n",
      "event000000026-cells.csv  event000000068-cells.csv  event000000110-cells.csv\r\n",
      "event000000026-hits.csv   event000000068-hits.csv   event000000110-hits.csv\r\n",
      "event000000027-cells.csv  event000000069-cells.csv  event000000111-cells.csv\r\n",
      "event000000027-hits.csv   event000000069-hits.csv   event000000111-hits.csv\r\n",
      "event000000028-cells.csv  event000000070-cells.csv  event000000112-cells.csv\r\n",
      "event000000028-hits.csv   event000000070-hits.csv   event000000112-hits.csv\r\n",
      "event000000029-cells.csv  event000000071-cells.csv  event000000113-cells.csv\r\n",
      "event000000029-hits.csv   event000000071-hits.csv   event000000113-hits.csv\r\n",
      "event000000030-cells.csv  event000000072-cells.csv  event000000114-cells.csv\r\n",
      "event000000030-hits.csv   event000000072-hits.csv   event000000114-hits.csv\r\n",
      "event000000031-cells.csv  event000000073-cells.csv  event000000115-cells.csv\r\n",
      "event000000031-hits.csv   event000000073-hits.csv   event000000115-hits.csv\r\n",
      "event000000032-cells.csv  event000000074-cells.csv  event000000116-cells.csv\r\n",
      "event000000032-hits.csv   event000000074-hits.csv   event000000116-hits.csv\r\n",
      "event000000033-cells.csv  event000000075-cells.csv  event000000117-cells.csv\r\n",
      "event000000033-hits.csv   event000000075-hits.csv   event000000117-hits.csv\r\n",
      "event000000034-cells.csv  event000000076-cells.csv  event000000118-cells.csv\r\n",
      "event000000034-hits.csv   event000000076-hits.csv   event000000118-hits.csv\r\n",
      "event000000035-cells.csv  event000000077-cells.csv  event000000119-cells.csv\r\n",
      "event000000035-hits.csv   event000000077-hits.csv   event000000119-hits.csv\r\n",
      "event000000036-cells.csv  event000000078-cells.csv  event000000120-cells.csv\r\n",
      "event000000036-hits.csv   event000000078-hits.csv   event000000120-hits.csv\r\n",
      "event000000037-cells.csv  event000000079-cells.csv  event000000121-cells.csv\r\n",
      "event000000037-hits.csv   event000000079-hits.csv   event000000121-hits.csv\r\n",
      "event000000038-cells.csv  event000000080-cells.csv  event000000122-cells.csv\r\n",
      "event000000038-hits.csv   event000000080-hits.csv   event000000122-hits.csv\r\n",
      "event000000039-cells.csv  event000000081-cells.csv  event000000123-cells.csv\r\n",
      "event000000039-hits.csv   event000000081-hits.csv   event000000123-hits.csv\r\n",
      "event000000040-cells.csv  event000000082-cells.csv  event000000124-cells.csv\r\n",
      "event000000040-hits.csv   event000000082-hits.csv   event000000124-hits.csv\r\n",
      "event000000041-cells.csv  event000000083-cells.csv\r\n",
      "event000000041-hits.csv   event000000083-hits.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls data/test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-60.826698</td>\n",
       "      <td>-4.16023</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-84.729401</td>\n",
       "      <td>-7.29528</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-42.592999</td>\n",
       "      <td>5.04875</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-62.497501</td>\n",
       "      <td>2.72992</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-66.203697</td>\n",
       "      <td>-10.60120</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id\n",
       "0       1 -60.826698  -4.16023 -1502.5          7         2          1\n",
       "1       2 -84.729401  -7.29528 -1502.5          7         2          1\n",
       "2       3 -42.592999   5.04875 -1502.5          7         2          1\n",
       "3       4 -62.497501   2.72992 -1502.5          7         2          1\n",
       "4       5 -66.203697 -10.60120 -1502.5          7         2          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itr =  load_dataset('data/test_data', parts=['hits','cells'])\n",
    "event_id, hits, cells = next(itr)\n",
    "hits.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NUM_SEEDS = 200\n",
    "track_candidates = np.random.rand(NUM_SEEDS, 10,3)\n",
    "test_hit_ids = np.random.randint(1,size=(NUM_SEEDS,10,1),high=10000)\n",
    "test_mses = np.random.rand(NUM_SEEDS,10,1)\n",
    "track_mapping = np.concatenate((test_mses,test_hit_ids), axis=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_disk_hits(hits_df):\n",
    "    hits_df['is_cylinder'] = hits_df.apply(lambda x: is_cylinder(x['volume_id'], x['layer_id']), axis = 1)\n",
    "    \n",
    "    return hits_df[hits_df.is_cylinder == True], hits_df[hits_df.is_cylinder == False]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "inputs\n",
    "\n",
    "track_candidates: tensor of shape [num_seeds x 10 x 3] 3 for r,phi,z\n",
    "\n",
    "track_candidates_map: tensor of shape [num_seeds x 10 x 2] 2 for mse, hit_ids\n",
    "\n",
    "\"\"\"\n",
    "def prune(track_candidates, track_candidates_map, hits_df, event_id):\n",
    "    start = time.time()\n",
    "    inner_time_accumulated = 0\n",
    "    hits_array = hits_df.values\n",
    "    hits_assigned = np.zeros (len (hits_array), dtype=bool)\n",
    "    good_tracks = []\n",
    "    track_mses = np.sum (track_candidates_map[:,:,0], axis = 1)\n",
    "    sorted_idxs = np.argsort (track_mses)\n",
    "    sorted_track_mapping = track_candidates_map[sorted_idxs]\n",
    "    for track in sorted_track_mapping:\n",
    "        temp_hit_ids = np.round (track[:,1]).astype (int)\n",
    "        valid_track = not np.sum (hits_assigned[temp_hit_ids-1])\n",
    "        if (valid_track):\n",
    "            hits_assigned[temp_hit_ids-1] = True\n",
    "            good_tracks.append (temp_hit_ids)\n",
    "            \n",
    "    super_combined = []\n",
    "    for track_id, track in enumerate(good_tracks):\n",
    "        reshaped_track = track.reshape((-1,1))\n",
    "        trackIds = np.full(reshaped_track.shape,track_id+1)\n",
    "        combined = np.concatenate((reshaped_track,trackIds),axis=1) #assuming trackID=0 will be for bad tracks\n",
    "        if (track_id == 0):\n",
    "            super_combined = combined\n",
    "        else:\n",
    "            super_combined = np.concatenate ([super_combined, combined])\n",
    "    \n",
    "    hit_ids = np.arange (1,len (hits_assigned) + 1)\n",
    "    unassigned_hit_ids = hit_ids[np.logical_not (hits_assigned)]\n",
    "    unassigned_hit_ids = unassigned_hit_ids.reshape ((-1,1))\n",
    "    trackIds = np.zeros (unassigned_hit_ids.shape)\n",
    "    combined = np.concatenate ((unassigned_hit_ids, trackIds), axis = 1)\n",
    "    super_combined = np.concatenate ([super_combined, combined])\n",
    "    \n",
    "    event_id_column = np.full ((super_combined.shape[0], 1), event_id)\n",
    "    super_combined = np.concatenate ([event_id_column, super_combined], axis = 1)\n",
    "    \n",
    "    return super_combined.astype (int)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def prune_old(track_candidates, track_candidates_map, hits_df, event_id):\n",
    "    start = time.time()\n",
    "    inner_time_accumulated = 0\n",
    "    cyl_only_hits, non_cyl_hits = remove_disk_hits(hits_df)\n",
    "    \n",
    "    bad_hit_ids = non_cyl_hits['hit_id'].values\n",
    "    dummy_track_id = np.zeros(bad_hit_ids.shape, dtype=np.int32)\n",
    "    event_ids = np.full(bad_hit_ids.shape, event_id, dtype=np.int32)\n",
    "    \n",
    "    ignored_tracks = pd.DataFrame({'event_id':event_ids, 'hit_id':bad_hit_ids, 'track_id':dummy_track_id})\n",
    "    \n",
    "    cyl_only_hits['assigned'] = False\n",
    "    cyl_only_hits['track_id'] = np.nan\n",
    "    track_id = 1\n",
    "    \n",
    "    out = np.take(track_candidates_map,[0], axis=2) # grab mse per hit per track\n",
    "    track_mses = np.sum(out,axis=1) #calc mse per track\n",
    "    sorted_idxs=np.argsort(track_mses, axis = 0)\n",
    "    #flat_idxs = sorted_idxs.flatten()\n",
    "    sorted_tracks = track_candidates[sorted_idxs]\n",
    "    sorted_track_mapping = track_candidates_map[sorted_idxs]\n",
    "\n",
    "    for batchIdx, batch in enumerate(sorted_tracks):\n",
    "        for trackIdx, track in enumerate(batch):\n",
    "            temp_hit_ids = []\n",
    "            valid_track = True\n",
    "\n",
    "            temp_hit_ids = sorted_track_mapping[batchIdx][trackIdx][:][1]\n",
    "            #for hitIdx, hit in enumerate(track): \n",
    "                #print(hit)\n",
    "                #hit_id = sorted_track_mapping[batchIdx][trackIdx][hitIdx][1]\n",
    "                #temp_hit_ids.append(hit_id)\n",
    "            inner_time_start = time.time()\n",
    "            for hit_id in temp_hit_ids:\n",
    "                if cyl_only_hits.loc[cyl_only_hits['hit_id']==hit_id]['assigned'] is True:\n",
    "                    valid_track = False\n",
    "                    break\n",
    "\n",
    "            if valid_track:\n",
    "                for hit_id in temp_hit_ids:\n",
    "                    cyl_only_hits.loc[cyl_only_hits['hit_id']==hit_id, 'assigned'] = True\n",
    "                    \n",
    "                    \n",
    "                    #idx = cyl_only_hits.loc[cyl_only_hits['hit_id']==hit_id].index\n",
    "                    #print('idx is: ',idx)\n",
    "                    cyl_only_hits.loc[cyl_only_hits['hit_id']==hit_id,'track_id'] = track_id\n",
    "                    #cyl_only_hits.at[idx,'assigned'] = track_id\n",
    "                    #df.at['C', 'x'] = 10\n",
    "                track_id +=1\n",
    "            inner_time_accumulated += (time.time() - inner_time_start)\n",
    "    \n",
    "    dropped_df = cyl_only_hits.drop(['x','y','z','volume_id','layer_id','module_id','is_cylinder','module_id'],axis=1)\n",
    "    \n",
    "   \n",
    "    final_results = dropped_df.fillna(0, downcast={np.float32,np.int32})     \n",
    "        \n",
    "    \n",
    "    \n",
    "    print ('inner time:' + str (inner_time_accumulated))\n",
    "    print('elasped time: '+str(time.time()-start))\n",
    "    return ignored_tracks, final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, _, _ , truth = load_data_single_event(1050)\n",
    "track_cand = np.load('./experimental/hits_from_tracks_event_1050.npy')\n",
    "mse_hitids = np.load('./experimental/mse_hitid_event_1050.npy')\n",
    "results = prune(track_cand, mse_hitids,hits, 1050)\n",
    "results_df = pd.DataFrame(data=results, columns = ['event_id', 'hit_id', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032376184563013916"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_event(truth,results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "for event_data in load_dataset ('./data/test_data', parts = ['hits']):\n",
    "    event_id = event_data[0]\n",
    "    print (event_id)\n",
    "    hits = event_data[1]\n",
    "    track_cand = np.load('./reconstructed_test_events/hits_from_tracks_event_' + str (event_id) + '.npy')\n",
    "    mapping = np.load('./reconstructed_test_events/mse_hitid_event_' + str (event_id) + '.npy')\n",
    "    our_result = prune (track_cand, mapping, hits, event_id)\n",
    "    our_result_df = pd.DataFrame (data = our_result, columns = ['event_id', 'hit_id', 'track_id'])\n",
    "    if (event_id == 0):\n",
    "        our_result_df.to_csv('./submission.csv', index = False)\n",
    "    else:\n",
    "        our_result_df.to_csv(open ('./submission.csv', 'a'), index = False, header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time:  0.16388845443725586\n",
      "   event_id  hit_id  track_id\n",
      "0      1050   20237         1\n",
      "1      1050   27501         1\n",
      "2      1050   33877         1\n",
      "3      1050   39687         1\n",
      "4      1050   69212         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.032376184563013916"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = np.load('./mse_hitid.npy')\n",
    "track_cand = np.load('./hits_from_tracks.npy')\n",
    "hits, _, _,truth = load_data_single_event(1050)\n",
    " \n",
    "start = time.time()\n",
    "results = prune(track_cand, mapping, hits, 1050)\n",
    "print('total time: ', time.time()-start)\n",
    "our_result = prune(track_cand, mapping, hits, 1050)\n",
    "#np.save ('./submission_sample.npy', our_result)\n",
    "our_result_df = pd.DataFrame (data = our_result, columns = ['event_id', 'hit_id', 'track_id'])\n",
    "print (our_result_df.head())\n",
    "score_event (truth, our_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id  hit_id  track_id\n",
      "0      1050   20237         1\n",
      "1      1050   27501         1\n",
      "2      1050   33877         1\n",
      "3      1050   39687         1\n",
      "4      1050   69212         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.032376184563013916"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track1 = np.arange(10)\n",
    "track2 = np.arange(10,20)\n",
    "tracks = np.concatenate(([track1],[track2]), axis=0 )\n",
    "len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission_from_good_tracks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3868235a0792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubmission_from_good_tracks\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission_from_good_tracks' is not defined"
     ]
    }
   ],
   "source": [
    "print (submission_from_good_tracks (results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "out = np.take(track_mapping,[0], axis=2) # grab mse per hit per track\n",
    "track_mses = np.sum(out,axis=1) #calc mse per track\n",
    "\n",
    "sorted_idxs=np.argsort(track_mses, axis = 0)\n",
    "#flat_idxs = sorted_idxs.flatten()\n",
    "sorted_tracks = track_candidates[sorted_idxs]\n",
    "\n",
    "sorted_track_mapping = track_mapping[sorted_idxs]\n",
    "\n",
    "\n",
    "\n",
    "hits_ref = hits #remember to pass the hits_df in!\n",
    "hits_ref['assigned']=False\n",
    "hits_ref['track_id'] = np.nan\n",
    "track_id = 1\n",
    "for batchIdx, batch in enumerate(sorted_tracks):\n",
    "    for trackIdx, track in enumerate(batch):\n",
    "        temp_hit_ids = []\n",
    "        valid_track = True\n",
    "        \n",
    "        for hitIdx, hit in enumerate(track): \n",
    "            #print(hit)\n",
    "            hit_id = sorted_track_mapping[batchIdx][trackIdx][hitIdx][1]\n",
    "            temp_hit_ids.append(hit_id)\n",
    "        \n",
    "        for hit_id in temp_hit_ids:\n",
    "            if hits_ref.loc[hits_ref['hit_id']==hit_id]['assigned'].item() is True:\n",
    "                valid_track = False\n",
    "                break\n",
    "        \n",
    "        \n",
    "        if valid_track:\n",
    "            for hit_id in temp_hit_ids:\n",
    "                hits_ref.loc[hits_ref['hit_id']==hit_id]['assigned'] = True\n",
    "                hits_ref.loc[hits_ref['hit_id']==hit_id]['track_id'] = track_id\n",
    "            track_id +=1\n",
    "            \n",
    "\n",
    "            \n",
    "\"\"\"             \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
