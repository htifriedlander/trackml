{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "total_layers = 10\n",
    "internal_dimension = 400\n",
    "linear_layer_dimension = 30\n",
    "#relu_layers = 2\n",
    "output_dimension = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.31738261840044, 72.15091393575189, 116.0946312221527, 172.07253929769357, 260.3569293324722, 360.3101542051449, 500.2151479081191, 660.12508634391, 820.1546870692688, 1020.1106909393304]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "#get hits dataframe\n",
    "hits, cells, particles, truth = load_single_train_event(1050)\n",
    "\n",
    "#transform to cylindrical\n",
    "hits_trans = trans_to_cylindrical (hits)\n",
    "\n",
    "hits_array = np.array (hits_trans.values)\n",
    "\n",
    "r_values = []\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 8) & (hits_trans['layer_id'] == 2)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 8) & (hits_trans['layer_id'] == 4)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 8) & (hits_trans['layer_id'] == 6)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 8) & (hits_trans['layer_id'] == 8)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 13) & (hits_trans['layer_id'] == 2)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 13) & (hits_trans['layer_id'] == 4)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 13) & (hits_trans['layer_id'] == 6)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 13) & (hits_trans['layer_id'] == 8)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 17) & (hits_trans['layer_id'] == 2)])['r'].get_values()))\n",
    "r_values.append (np.average ((hits_trans.loc[(hits_trans['volume_id'] == 17) & (hits_trans['layer_id'] == 4)])['r'].get_values()))\n",
    "print (r_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predict_engine:\n",
    "    def create_layer_learner (input_layers, x):\n",
    "        input_dimension = 2*(input_layers)\n",
    "        x_trimmed = x[:,:input_dimension]\n",
    "        #x_trimmed = tf.slice (x, [0,0], [x.shape[0],input_dimension])\n",
    "        W = tf.Variable (tf.random_normal ([input_dimension,internal_dimension], stddev = 1/np.sqrt (internal_dimension)))\n",
    "        b = tf.Variable (tf.zeros ([internal_dimension]))\n",
    "        y = tf.nn.leaky_relu (tf.add (tf.matmul (x_trimmed, W), b))\n",
    "        W = tf.Variable (tf.random_normal ([internal_dimension,linear_layer_dimension], stddev = 1/np.sqrt (internal_dimension)))\n",
    "        b = tf.Variable (tf.zeros ([linear_layer_dimension]))\n",
    "        y = tf.nn.leaky_relu (tf.add (tf.matmul (y, W), b))\n",
    "        W = tf.Variable (tf.random_normal ([linear_layer_dimension, output_dimension], stddev = 1/np.sqrt (linear_layer_dimension)))\n",
    "        b = tf.Variable (tf.zeros ([output_dimension]))\n",
    "        y = tf.add (tf.matmul (y, W), b)\n",
    "        return y\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.x = tf.placeholder (tf.float32, [None, 20])\n",
    "        y_target = self.x[:,6:20]\n",
    "        y = []\n",
    "        for i in range (3,10):\n",
    "            y.append (predict_engine.create_layer_learner (i, self.x))\n",
    "        self.y = tf.concat (y,1)\n",
    "        self.mean_squared_error = tf.reduce_mean (tf.square (tf.subtract (self.y, y_target)))\n",
    "        optimizer = tf.train.AdamOptimizer (learning_rate = 0.001)\n",
    "        self.minimize_op = optimizer.minimize (self.mean_squared_error)\n",
    "        self.session = tf.Session()\n",
    "        self.session.run (tf.global_variables_initializer())\n",
    "        \n",
    "    def train(self):\n",
    "        input_layers = total_layers-1\n",
    "        counter = 0\n",
    "        mseList = []\n",
    "\n",
    "        for batch in next_batch (10,batch_size,5, ideal = True, full_data=True):\n",
    "            batch_array = np.array (batch[0])[:,:,1:3]\n",
    "            for i in range(len(batch_array)):\n",
    "                if (np.abs (batch_array[i, 0, 0]) > np.pi/2):\n",
    "                    do_quadrant_shift = True\n",
    "                else:\n",
    "                    do_quadrant_shift = False\n",
    "                for j in range(len(batch_array[i])):\n",
    "                    if (do_quadrant_shift):\n",
    "                        batch_array[i, j, 0] = quadrant_shift (batch_array[i, j, 0])\n",
    "                    batch_array[i,j,0] = batch_array[i,j,0]/np.pi \n",
    "                    batch_array[i,j,1] = batch_array[i,j,1]/1200 \n",
    "            batch_array_flattened = [batch_array[i].flatten() for i in range(len(batch_array))]\n",
    "            batch_array_flattened = np.array (batch_array_flattened)    \n",
    "\n",
    "            print (\"loss is ...\")\n",
    "            prediction = self.session.run (self.y, feed_dict = {self.x:batch_array_flattened[0:1]})\n",
    "            loss = self.session.run (self.mean_squared_error, feed_dict = {self.x:batch_array_flattened})\n",
    "            print (loss)\n",
    "            mseList.append (loss)\n",
    "            self.session.run (self.minimize_op, feed_dict = {self.x:batch_array_flattened})\n",
    "\n",
    "            predicted = []\n",
    "            for i in range(0, total_layers-3):\n",
    "                predicted.append (prediction[0,2*i])\n",
    "\n",
    "            plt.scatter (batch_array[0][:,0], range (len(batch_array[0])), color = 'blue')\n",
    "            plt.scatter (predicted, range (3, input_layers+1), color = 'cyan')\n",
    "            plt.axis ([-1,2,-1,input_layers+1])\n",
    "            plt.show ()\n",
    "            plt.scatter (range(len(mseList)), np.log(mseList))\n",
    "            plt.show()\n",
    "            print (counter)\n",
    "\n",
    "            counter += 1\n",
    "            if (counter >= 1000):\n",
    "                break\n",
    "                \n",
    "    def load(self):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore (self.session, './checkpoints/allv1/model.ckpt')\n",
    "\n",
    "    def pred(self, inputs):#inputs are a list of [r, phi, z, l, v] with length 10\n",
    "        inputs = np.array (inputs)\n",
    "        for i in range (len (inputs)):\n",
    "            inputs[i,1] = inputs[i,1]/np.pi\n",
    "            inputs[i,2] = inputs[i,2]/1200\n",
    "        trimmed_inputs = [inputs[:,1:3].flatten()]\n",
    "        padding = [np.zeros (20 - len (trimmed_inputs[0]))]\n",
    "        trimmed_inputs = np.concatenate ((trimmed_inputs, padding), axis = 1)\n",
    "        prediction = self.session.run (self.y, feed_dict = {self.x:trimmed_inputs})\n",
    "        toReturn = np.zeros ([10,3])\n",
    "        for i in range (2,9):\n",
    "            toReturn[i,0] = r_values[i+1]\n",
    "            toReturn[i,1] = prediction[0,2*i-4]*np.pi\n",
    "            toReturn[i,2] = prediction[0,2*i-3]*1200\n",
    "        return toReturn\n",
    "        #should return 10x3.   track x [r, phi, z]\n",
    "\n",
    "    def close(self):\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
